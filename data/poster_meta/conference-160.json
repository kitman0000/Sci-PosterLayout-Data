{"poster_size": 12441600, "doclen": 381, "figlen": 3663800, "section": {"0": {"xy": [1387, 35, 1536, 191], "panel_size": 293376, "panel_aspectRatio": 8.041884816753926, "category": "Title", "figures": 0, "textlen": 0, "fig_size": 0, "title": "Counterfactual Fairness", "textRatio": 0.0, "figRatio": 0.0}, "1": {"xy": [93, 366, 1428, 893], "panel_size": 1275204, "panel_aspectRatio": 1.599104143337066, "category": "Introduction", "figures": 2, "textlen": 61, "fig_size": 240973, "title": "ML is making Life-Changing Decisions", "3": {"fig_size": 133488, "fig_aspectRatio": 3.145631067961165, "fig_size_poster": 0.453781512605042}, "4": {"fig_size": 107485, "fig_aspectRatio": 3.1405405405405404, "fig_size_poster": 0.4068627450980392}, "textRatio": 0.16010498687664043, "figRatio": 0.06577133031279}, "7": {"xy": [116, 1283, 1350, 1557], "panel_size": 2101950, "panel_aspectRatio": 0.8670520231213873, "category": "Method", "figures": 6, "textlen": 127, "fig_size": 551801, "title": "Law School Admissions", "10": {"fig_size": 275110, "fig_aspectRatio": 1.6365853658536584, "fig_size_poster": 0.49703703703703705}, "17": {"fig_size": 50518, "fig_aspectRatio": 2.8134328358208953, "fig_size_poster": 0.27925925925925926}, "20": {"fig_size": 72627, "fig_aspectRatio": 4.364341085271318, "fig_size_poster": 0.41703703703703704}, "22": {"fig_size": 81006, "fig_aspectRatio": 4.253623188405797, "fig_size_poster": 0.4348148148148148}, "24": {"fig_size": 68820, "fig_aspectRatio": 4.475806451612903, "fig_size_poster": 0.4111111111111111}, "26": {"fig_size": 3720, "fig_aspectRatio": 1.0333333333333334, "fig_size_poster": 0.045925925925925926}, "textRatio": 0.3333333333333333, "figRatio": 0.15060893061848354}, "29": {"xy": [1535, 353, 1296, 1150], "panel_size": 1490400, "panel_aspectRatio": 1.1269565217391304, "category": "Method", "figures": 7, "textlen": 33, "fig_size": 685861, "title": "Causal Inference\n[Pearl et al., 2016]", "30": {"fig_size": 253774, "fig_aspectRatio": 1.2757847533632287, "fig_size_poster": 0.4390432098765432}, "33": {"fig_size": 48675, "fig_aspectRatio": 1.5536723163841808, "fig_size_poster": 0.21219135802469136}, "35": {"fig_size": 64416, "fig_aspectRatio": 1.9234972677595628, "fig_size_poster": 0.2716049382716049}, "39": {"fig_size": 74046, "fig_aspectRatio": 4.894308943089431, "fig_size_poster": 0.4645061728395062}, "41": {"fig_size": 78672, "fig_aspectRatio": 4.515151515151516, "fig_size_poster": 0.45987654320987653}, "43": {"fig_size": 83754, "fig_aspectRatio": 4.212765957446808, "fig_size_poster": 0.4583333333333333}, "45": {"fig_size": 82524, "fig_aspectRatio": 4.333333333333333, "fig_size_poster": 0.46141975308641975}, "textRatio": 0.08661417322834646, "figRatio": 0.18719935586003603}, "46": {"xy": [1500, 1552, 1373, 978], "panel_size": 1342794, "panel_aspectRatio": 1.403885480572597, "category": "Method", "figures": 5, "textlen": 67, "fig_size": 391255, "title": "Counterfactual Fairness", "48": {"fig_size": 54810, "fig_aspectRatio": 16.29310344827586, "fig_size_poster": 0.6882738528769119}, "53": {"fig_size": 214038, "fig_aspectRatio": 1.1962174940898345, "fig_size_poster": 0.3685360524399126}, "56": {"fig_size": 22344, "fig_aspectRatio": 7.125, "fig_size_poster": 0.2906045156591406}, "58": {"fig_size": 28272, "fig_aspectRatio": 12.270833333333334, "fig_size_poster": 0.4289876183539694}, "59": {"fig_size": 71791, "fig_aspectRatio": 6.766990291262136, "fig_size_poster": 0.507647487254188}, "textRatio": 0.17585301837270342, "figRatio": 0.10678939898466074}, "64": {"xy": [1514, 2568, 1341, 231], "panel_size": 309771, "panel_aspectRatio": 5.805194805194805, "category": "Method", "figures": 1, "textlen": 12, "fig_size": 67689, "title": "Related Work", "67": {"fig_size": 67689, "fig_aspectRatio": 14.217391304347826, "fig_size_poster": 0.7315436241610739}, "textRatio": 0.031496062992125984, "figRatio": 0.018475080517495496}, "68": {"xy": [2882, 362, 1341, 2450], "panel_size": 3285450, "panel_aspectRatio": 0.5473469387755102, "category": "Result", "figures": 7, "textlen": 81, "fig_size": 1726221, "title": "Results: US law schools", "76": {"fig_size": 144282, "fig_aspectRatio": 1.2052023121387283, "fig_size_poster": 0.31096196868008946}, "77": {"fig_size": 170392, "fig_aspectRatio": 1.3074792243767313, "fig_size_poster": 0.35197613721103654}, "79": {"fig_size": 187340, "fig_aspectRatio": 6.482352941176471, "fig_size_poster": 0.8217747949291574}, "81": {"fig_size": 719075, "fig_aspectRatio": 2.0868824531516186, "fig_size_poster": 0.9134973900074571}, "84": {"fig_size": 167688, "fig_aspectRatio": 1.0073529411764706, "fig_size_poster": 0.30648769574944074}, "86": {"fig_size": 166464, "fig_aspectRatio": 1.0, "fig_size_poster": 0.3042505592841163}, "88": {"fig_size": 170980, "fig_aspectRatio": 0.9927710843373494, "fig_size_poster": 0.30723340790454884}, "textRatio": 0.2125984251968504, "figRatio": 0.4711559037065342}}}