{"poster_size": 4478976, "doclen": 126, "figlen": 2004168, "section": {"1": {"xy": [826, 812, 1749, 750], "panel_size": 1311750, "panel_aspectRatio": 2.332, "category": "Result", "figures": 1, "textlen": 0, "fig_size": 1080732, "title": "Experimental Results", "2": {"fig_size": 1080732, "fig_aspectRatio": 2.3510324483775813, "fig_size_poster": 0.9113779302458548}, "textRatio": 0.0, "figRatio": 0.5392422192151556}, "3": {"xy": [28, 758, 784, 803], "panel_size": 629552, "panel_aspectRatio": 0.9763387297633873, "category": "Result", "figures": 2, "textlen": 0, "fig_size": 414204, "title": "Feature Comparison", "4": {"fig_size": 207502, "fig_aspectRatio": 1.6100278551532032, "fig_size_poster": 0.7372448979591837}, "5": {"fig_size": 206702, "fig_aspectRatio": 1.5773480662983426, "fig_size_poster": 0.7283163265306123}, "textRatio": 0.0, "figRatio": 0.20667129701701653}, "6": {"xy": [840, 251, 1711, 539], "panel_size": 922229, "panel_aspectRatio": 3.174397031539889, "category": "Method", "figures": 3, "textlen": 47, "fig_size": 509232, "title": "Methodology", "7": {"fig_size": 225126, "fig_aspectRatio": 5.742424242424242, "fig_size_poster": 0.6645236703682057}, "8": {"fig_size": 232696, "fig_aspectRatio": 1.0444915254237288, "fig_size_poster": 0.288135593220339}, "9": {"fig_size": 51410, "fig_aspectRatio": 1.365979381443299, "fig_size_poster": 0.1548801870251315}, "textRatio": 0.373015873015873, "figRatio": 0.25408648376782783}, "13": {"xy": [30, 242, 773, 497], "panel_size": 384181, "panel_aspectRatio": 1.5553319919517103, "category": "Introduction", "figures": 0, "textlen": 79, "fig_size": 0, "title": "Motivation", "textRatio": 0.626984126984127, "figRatio": 0.0}, "15": {"xy": [32, 7, 2550, 95], "panel_size": 242250, "panel_aspectRatio": 26.842105263157894, "category": "Title", "figures": 0, "textlen": 0, "fig_size": 0, "title": "Sound Texture Classification Using Statistics from an Auditory Model", "textRatio": 0.0, "figRatio": 0.0}}}