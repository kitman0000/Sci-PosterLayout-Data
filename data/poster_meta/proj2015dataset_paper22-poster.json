{"poster_size": 484704, "doclen": 280, "figlen": 128871, "section": {"1": {"xy": [191, 48, 412, 21], "panel_size": 8652, "panel_aspectRatio": 19.61904761904762, "category": "Title", "figures": 0, "textlen": 0, "fig_size": 0, "title": "Automatic Rhythm Notation from Single Voice Audio Sources", "textRatio": 0.0, "figRatio": 0.0}, "2": {"xy": [183, 107, 429, 230], "panel_size": 98670, "panel_aspectRatio": 1.8652173913043477, "category": "Method", "figures": 3, "textlen": 20, "fig_size": 50379, "title": "NA", "3": {"fig_size": 31616, "fig_aspectRatio": 5.473684210526316, "fig_size_poster": 0.9696969696969697}, "4": {"fig_size": 5633, "fig_aspectRatio": 0.3282442748091603, "fig_size_poster": 0.10023310023310024}, "5": {"fig_size": 13130, "fig_aspectRatio": 0.7769230769230769, "fig_size_poster": 0.23543123543123542}, "textRatio": 0.07142857142857142, "figRatio": 0.3909258095304607}, "7": {"xy": [612, 43, 171, 267], "panel_size": 45657, "panel_aspectRatio": 0.6404494382022472, "category": "Result", "figures": 0, "textlen": 74, "fig_size": 0, "title": "Results & Future Directions", "textRatio": 0.2642857142857143, "figRatio": 0.0}, "9": {"xy": [3, 48, 176, 240], "panel_size": 42240, "panel_aspectRatio": 0.7333333333333333, "category": "Introduction", "figures": 0, "textlen": 76, "fig_size": 0, "title": "The Data& The Challenges", "textRatio": 0.2714285714285714, "figRatio": 0.0}, "11": {"xy": [12, 339, 773, 240], "panel_size": 185520, "panel_aspectRatio": 3.220833333333333, "category": "Method", "figures": 1, "textlen": 110, "fig_size": 78492, "title": "Methods", "13": {"fig_size": 78492, "fig_aspectRatio": 1.7630331753554502, "fig_size_poster": 0.48124191461837}, "textRatio": 0.39285714285714285, "figRatio": 0.6090741904695393}}}