{"poster_size": 4478976, "doclen": 58, "figlen": 1836095, "section": {"1": {"xy": [389, 97, 2123, 95], "panel_size": 201685, "panel_aspectRatio": 22.347368421052632, "category": "Title", "figures": 0, "textlen": 0, "fig_size": 0, "title": "CS229: Machine Learning for Human Activity Recognition from Video", "textRatio": 0.0, "figRatio": 0.0}, "2": {"xy": [2, 341, 885, 482], "panel_size": 426570, "panel_aspectRatio": 1.8360995850622406, "category": "Introduction", "figures": 2, "textlen": 10, "fig_size": 278988, "title": "Motivation - Real-world Activity Recognition", "3": {"fig_size": 142710, "fig_aspectRatio": 1.2716417910447761, "fig_size_poster": 0.48135593220338985}, "4": {"fig_size": 136278, "fig_aspectRatio": 1.1858407079646018, "fig_size_poster": 0.4542372881355932}, "textRatio": 0.1724137931034483, "figRatio": 0.15194638621639947}, "6": {"xy": [23, 825, 842, 449], "panel_size": 378058, "panel_aspectRatio": 1.8752783964365256, "category": "Method", "figures": 1, "textlen": 0, "fig_size": 296745, "title": "Chosen Method - Multi-Stream Late Fusion", "7": {"fig_size": 296745, "fig_aspectRatio": 2.2273972602739724, "fig_size_poster": 0.9655581947743468}, "textRatio": 0.0, "figRatio": 0.16161745443454723}, "8": {"xy": [34, 1280, 796, 409], "panel_size": 325564, "panel_aspectRatio": 1.9462102689486553, "category": "Result", "figures": 3, "textlen": 0, "fig_size": 216090, "title": "Results-Quantitative", "9": {"fig_size": 80522, "fig_aspectRatio": 1.319838056680162, "fig_size_poster": 0.40954773869346733}, "10": {"fig_size": 88576, "fig_aspectRatio": 1.3515625, "fig_size_poster": 0.43467336683417085}, "11": {"fig_size": 46992, "fig_aspectRatio": 5.932584269662922, "fig_size_poster": 0.6633165829145728}, "textRatio": 0.0, "figRatio": 0.11768998880776867}, "12": {"xy": [887, 830, 838, 416], "panel_size": 348608, "panel_aspectRatio": 2.014423076923077, "category": "Result", "figures": 4, "textlen": 0, "fig_size": 260608, "title": "Results-Qualitative[Recognition]", "13": {"fig_size": 66748, "fig_aspectRatio": 2.481707317073171, "fig_size_poster": 0.48568019093078757}, "14": {"fig_size": 63600, "fig_aspectRatio": 2.5157232704402515, "fig_size_poster": 0.477326968973747}, "15": {"fig_size": 66660, "fig_aspectRatio": 2.4484848484848483, "fig_size_poster": 0.4821002386634845}, "16": {"fig_size": 63600, "fig_aspectRatio": 2.5157232704402515, "fig_size_poster": 0.477326968973747}, "textRatio": 0.0, "figRatio": 0.1419360109362533}, "17": {"xy": [897, 352, 846, 460], "panel_size": 389160, "panel_aspectRatio": 1.8391304347826087, "category": "Method", "figures": 1, "textlen": 0, "fig_size": 310338, "title": "Dataset - Charades from Allen Institute", "18": {"fig_size": 310338, "fig_aspectRatio": 2.171957671957672, "fig_size_poster": 0.9704491725768322}, "textRatio": 0.0, "figRatio": 0.16902066614200245}, "19": {"xy": [886, 1276, 805, 371], "panel_size": 298655, "panel_aspectRatio": 2.169811320754717, "category": "Result", "figures": 0, "textlen": 48, "fig_size": 0, "title": "Conclusions", "textRatio": 0.8275862068965517, "figRatio": 0.0}, "21": {"xy": [1754, 356, 824, 470], "panel_size": 387280, "panel_aspectRatio": 1.7531914893617022, "category": "Method", "figures": 4, "textlen": 0, "fig_size": 211780, "title": "Video Activity Recognition - Available Methods", "22": {"fig_size": 56771, "fig_aspectRatio": 2.7762237762237763, "fig_size_poster": 0.4817961165048544}, "23": {"fig_size": 56320, "fig_aspectRatio": 2.2, "fig_size_poster": 0.42718446601941745}, "24": {"fig_size": 54312, "fig_aspectRatio": 2.547945205479452, "fig_size_poster": 0.45145631067961167}, "25": {"fig_size": 44377, "fig_aspectRatio": 1.120603015075377, "fig_size_poster": 0.27063106796116504}, "textRatio": 0.0, "figRatio": 0.11534261571432851}, "26": {"xy": [1736, 841, 839, 403], "panel_size": 338117, "panel_aspectRatio": 2.0818858560794045, "category": "Result", "figures": 4, "textlen": 0, "fig_size": 261546, "title": "Results-Qualitative[Retrieval]", "27": {"fig_size": 66825, "fig_aspectRatio": 2.4545454545454546, "fig_size_poster": 0.4827175208581645}, "28": {"fig_size": 69121, "fig_aspectRatio": 2.4201183431952664, "fig_size_poster": 0.48748510131108463}, "29": {"fig_size": 63200, "fig_aspectRatio": 2.5316455696202533, "fig_size_poster": 0.4767580452920143}, "30": {"fig_size": 62400, "fig_aspectRatio": 2.5641025641025643, "fig_size_poster": 0.4767580452920143}, "textRatio": 0.0, "figRatio": 0.14244687774870038}}}