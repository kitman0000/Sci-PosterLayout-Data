{"poster_size": 3110400, "doclen": 444, "figlen": 596799, "section": {"1": {"xy": [569, 24, 1076, 83], "panel_size": 89308, "panel_aspectRatio": 12.963855421686747, "category": "Title", "figures": 0, "textlen": 0, "fig_size": 0, "title": "Context Is Everything: Finding Meaning Statistically in Semantic Spaces", "textRatio": 0.0, "figRatio": 0.0}, "2": {"xy": [0, 120, 671, 447], "panel_size": 299937, "panel_aspectRatio": 1.5011185682326622, "category": "Introduction", "figures": 0, "textlen": 64, "fig_size": 0, "title": "Overview", "textRatio": 0.14414414414414414, "figRatio": 0.0}, "4": {"xy": [723, 130, 709, 451], "panel_size": 319759, "panel_aspectRatio": 1.5720620842572062, "category": "Method", "figures": 3, "textlen": 31, "fig_size": 133085, "title": "Algorithms: Word Vector Clouds", "6": {"fig_size": 26832, "fig_aspectRatio": 17.641025641025642, "fig_size_poster": 0.9703808180535967}, "7": {"fig_size": 52640, "fig_aspectRatio": 2.05625, "fig_size_poster": 0.46403385049365303}, "8": {"fig_size": 53613, "fig_aspectRatio": 2.0683229813664594, "fig_size_poster": 0.4696755994358251}, "textRatio": 0.06981981981981981, "figRatio": 0.2229980278117088}, "9": {"xy": [18, 590, 671, 370], "panel_size": 248270, "panel_aspectRatio": 1.8135135135135134, "category": "Introduction", "figures": 0, "textlen": 58, "fig_size": 0, "title": "Current Implementation Limitations", "textRatio": 0.13063063063063063, "figRatio": 0.0}, "12": {"xy": [14, 969, 692, 464], "panel_size": 321088, "panel_aspectRatio": 1.4913793103448276, "category": "Introduction", "figures": 0, "textlen": 76, "fig_size": 0, "title": "Motivation", "textRatio": 0.17117117117117117, "figRatio": 0.0}, "15": {"xy": [712, 592, 720, 374], "panel_size": 269280, "panel_aspectRatio": 1.9251336898395721, "category": "Method", "figures": 0, "textlen": 65, "fig_size": 0, "title": "Algorithms: Sentence Embeddings", "textRatio": 0.1463963963963964, "figRatio": 0.0}, "17": {"xy": [778, 978, 653, 425], "panel_size": 277525, "panel_aspectRatio": 1.536470588235294, "category": "Method", "figures": 0, "textlen": 73, "fig_size": 0, "title": "Algorithms: Sentence Unembeddings", "textRatio": 0.16441441441441443, "figRatio": 0.0}, "19": {"xy": [1446, 110, 705, 851], "panel_size": 599955, "panel_aspectRatio": 0.8284371327849589, "category": "Result", "figures": 4, "textlen": 0, "fig_size": 463714, "title": "", "20": {"fig_size": 124656, "fig_aspectRatio": 1.2327044025157232, "fig_size_poster": 0.5560283687943263}, "21": {"fig_size": 57564, "fig_aspectRatio": 0.4672364672364672, "fig_size_poster": 0.2326241134751773}, "22": {"fig_size": 181654, "fig_aspectRatio": 1.4094707520891365, "fig_size_poster": 0.7177304964539007}, "23": {"fig_size": 99840, "fig_aspectRatio": 4.102564102564102, "fig_size_poster": 0.9078014184397163}, "textRatio": 0.0, "figRatio": 0.7770019721882911}, "24": {"xy": [1458, 972, 677, 426], "panel_size": 288402, "panel_aspectRatio": 1.5892018779342723, "category": "Discussion", "figures": 0, "textlen": 77, "fig_size": 0, "title": "Conclusion and Future Directions", "textRatio": 0.17342342342342343, "figRatio": 0.0}}}