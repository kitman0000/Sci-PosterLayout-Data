{"poster_size": 4478976, "doclen": 238, "figlen": 1629789, "section": {"1": {"xy": [563, 30, 1734, 93], "panel_size": 161262, "panel_aspectRatio": 18.64516129032258, "category": "Title", "figures": 0, "textlen": 0, "fig_size": 0, "title": "Quixote: A NetHack Reinforcement Learning Framework and Agent", "textRatio": 0.0, "figRatio": 0.0}, "2": {"xy": [4, 299, 382, 1266], "panel_size": 483612, "panel_aspectRatio": 0.30173775671406006, "category": "Introduction", "figures": 0, "textlen": 122, "fig_size": 0, "title": "Abstract", "textRatio": 0.5126050420168067, "figRatio": 0.0}, "4": {"xy": [413, 308, 532, 761], "panel_size": 404852, "panel_aspectRatio": 0.6990801576872536, "category": "Introduction", "figures": 1, "textlen": 17, "fig_size": 236900, "title": "Objective", "6": {"fig_size": 236900, "fig_aspectRatio": 1.1195652173913044, "fig_size_poster": 0.9680451127819549}, "textRatio": 0.07142857142857142, "figRatio": 0.14535623936595474}, "7": {"xy": [397, 1076, 563, 623], "panel_size": 350749, "panel_aspectRatio": 0.9036918138041734, "category": "Method", "figures": 1, "textlen": 0, "fig_size": 240248, "title": "Framework", "8": {"fig_size": 240248, "fig_aspectRatio": 1.0783898305084745, "fig_size_poster": 0.9040852575488455}, "textRatio": 0.0, "figRatio": 0.14741049301473994}, "9": {"xy": [949, 315, 527, 1060], "panel_size": 558620, "panel_aspectRatio": 0.4971698113207547, "category": "Method", "figures": 3, "textlen": 0, "fig_size": 463809, "title": "Model 1: Basic Q-learning", "10": {"fig_size": 149527, "fig_aspectRatio": 1.8153310104529616, "fig_size_poster": 0.9886148007590133}, "11": {"fig_size": 197722, "fig_aspectRatio": 1.1995073891625616, "fig_size_poster": 0.9240986717267552}, "12": {"fig_size": 116560, "fig_aspectRatio": 2.1106382978723404, "fig_size_poster": 0.9411764705882353}, "textRatio": 0.0, "figRatio": 0.28458223733256266}, "13": {"xy": [969, 1375, 513, 313], "panel_size": 160569, "panel_aspectRatio": 1.6389776357827477, "category": "Method", "figures": 1, "textlen": 0, "fig_size": 119280, "title": "Model 2: Approximate Q-Learning", "14": {"fig_size": 119280, "fig_aspectRatio": 2.0708333333333333, "fig_size_poster": 0.9688109161793372}, "textRatio": 0.0, "figRatio": 0.07318738806066306}, "15": {"xy": [1500, 304, 519, 448], "panel_size": 232512, "panel_aspectRatio": 1.1584821428571428, "category": "Method", "figures": 0, "textlen": 16, "fig_size": 0, "title": "Model 3: E Scheduling", "textRatio": 0.06722689075630252, "figRatio": 0.0}, "18": {"xy": [1497, 769, 529, 506], "panel_size": 267674, "panel_aspectRatio": 1.0454545454545454, "category": "Result", "figures": 2, "textlen": 0, "fig_size": 210388, "title": "Results", "19": {"fig_size": 59553, "fig_aspectRatio": 4.35042735042735, "fig_size_poster": 0.9621928166351607}, "20": {"fig_size": 150835, "fig_aspectRatio": 1.5594855305466238, "fig_size_poster": 0.9168241965973535}, "textRatio": 0.0, "figRatio": 0.12908910294522788}, "21": {"xy": [1499, 1276, 537, 432], "panel_size": 231984, "panel_aspectRatio": 1.2430555555555556, "category": "Discussion", "figures": 0, "textlen": 57, "fig_size": 0, "title": "Discussion", "textRatio": 0.23949579831932774, "figRatio": 0.0}, "23": {"xy": [2041, 375, 541, 1044], "panel_size": 564804, "panel_aspectRatio": 0.5181992337164751, "category": "Method", "figures": 2, "textlen": 26, "fig_size": 359164, "title": "Future Directions", "25": {"fig_size": 161470, "fig_aspectRatio": 1.4388059701492537, "fig_size_poster": 0.8909426987060998}, "26": {"fig_size": 197694, "fig_aspectRatio": 1.3835978835978835, "fig_size_poster": 0.966728280961183}, "textRatio": 0.1092436974789916, "figRatio": 0.22037453928085168}}}